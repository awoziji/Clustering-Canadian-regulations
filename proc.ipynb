{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "csvfile = '../Semantic-Analysis-Regulations/regulations_data_analysis.csv'\n",
    "\n",
    "with open(csvfile, 'r') as f:\n",
    "    df = pd.read_csv(f)\n",
    "    long_titles = df['long_title']\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(title: str):\n",
    "    # Tokenize\n",
    "    tokenized_title: List[str] = nltk.word_tokenize(title)\n",
    "    \n",
    "    # Remove unwanted words (numbers and stopwords)\n",
    "    stops = stopwords.words('english')\n",
    "    # TODO: Do we need to filter out numbers?\n",
    "    tokenized_title = [token for token in tokenized_title\n",
    "                       if re.match(r'.*[A-Za-z].*', token) \n",
    "                       and token not in stops]\n",
    "\n",
    "    # Stemming\n",
    "    # https://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(token) for token in tokenized_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=tokenize) # TODO: min_df and max_df could be set to filter out some words\n",
    "tf_idf = vectorizer.fit_transform(long_titles)\n",
    "print(tf_idf.toarray())\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
